{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìÑ Explore Raw Documents (extended)\n",
        "\n",
        "–¶–µ–π –Ω–æ—É—Ç–±—É–∫:\n",
        "- –ø–æ–∫–∞–∑—É—î –≤—Å—ñ —Ñ–∞–π–ª–∏ —É `data/raw/`\n",
        "- —Ä–∞—Ö—É—î –±–∞–∑–æ–≤—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (—Å–∏–º–≤–æ–ª–∏/—Ä—è–¥–∫–∏/—Å–ª–æ–≤–∞)\n",
        "- –ø–µ—Ä–µ–≤—ñ—Ä—è—î, —á–∏ —î —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è BioConsult: `–ì–†–£–ü–ê –ó–ê–ü–ò–¢–£:` / `–ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞:` / `–í—ñ–¥–ø–æ–≤—ñ–¥—å:`\n",
        "- –∑–Ω–∞—Ö–æ–¥–∏—Ç—å —Å–º—ñ—Ç—Ç—è —Ç–∏–ø—É `=====` / `-----` —ñ –ø—ñ–¥—Å–≤—ñ—á—É—î, –≤ —è–∫–∏—Ö —Ñ–∞–π–ª–∞—Ö —î\n",
        "- —Ä–æ–±–∏—Ç—å –ø—Ä–µ–≤‚Äô—é –∑–Ω–∞–π–¥–µ–Ω–∏—Ö –≥—Ä—É–ø (–Ω–∞–∑–≤–∞ + –∫–ª—é—á—ñ + –ø–µ—Ä—à—ñ —Ä—è–¥–∫–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "RAW_DIR = Path(\"../data/raw\")\n",
        "print(\"üìÇ RAW_DIR:\", RAW_DIR.resolve())\n",
        "\n",
        "def safe_read(p: Path):\n",
        "    try:\n",
        "        return p.read_text(encoding=\"utf-8\"), None\n",
        "    except Exception as e:\n",
        "        return None, e\n",
        "\n",
        "def basic_stats(text: str):\n",
        "    lines = text.splitlines()\n",
        "    words = re.findall(r\"\\b[\\w‚Äô']+\\b\", text, flags=re.UNICODE)\n",
        "    return {\n",
        "        \"chars\": len(text),\n",
        "        \"lines\": len(lines),\n",
        "        \"words\": len(words),\n",
        "    }\n",
        "\n",
        "SEP_RE = re.compile(r\"^(={3,}|-{3,}|_{3,}|\\*{3,})\\s*$\")\n",
        "\n",
        "GROUP_RE = re.compile(r\"^–ì–†–£–ü–ê\\s+–ó–ê–ü–ò–¢–£:\\s*(.+)\\s*$\", re.IGNORECASE)\n",
        "KEYS_RE  = re.compile(r\"^–ö–ª—é—á–æ–≤—ñ\\s+—Å–ª–æ–≤–∞:\\s*(.+)\\s*$\", re.IGNORECASE)\n",
        "ANS_RE   = re.compile(r\"^–í—ñ–¥–ø–æ–≤—ñ–¥—å:\\s*$\", re.IGNORECASE)\n",
        "\n",
        "def parse_groups(txt: str):\n",
        "    \"\"\"–ü–∞—Ä—Å–µ—Ä –ø—ñ–¥ —Ñ–æ—Ä–º–∞—Ç BioConsult.\"\"\"\n",
        "    lines = txt.splitlines()\n",
        "    groups = []\n",
        "    cur = None\n",
        "    mode = None  # None | 'ans'\n",
        "\n",
        "    for raw in lines:\n",
        "        line = raw.rstrip(\"\\n\")\n",
        "\n",
        "        mG = GROUP_RE.match(line.strip())\n",
        "        if mG:\n",
        "            if cur:\n",
        "                cur[\"answer\"] = cur[\"answer\"].strip()\n",
        "                groups.append(cur)\n",
        "            cur = {\"title\": mG.group(1).strip(), \"keys\": [], \"answer\": \"\"}\n",
        "            mode = None\n",
        "            continue\n",
        "\n",
        "        if cur is None:\n",
        "            continue\n",
        "\n",
        "        mK = KEYS_RE.match(line.strip())\n",
        "        if mK:\n",
        "            keys_line = mK.group(1).strip()\n",
        "            keys = [k.strip() for k in keys_line.split(\",\") if k.strip()]\n",
        "            cur[\"keys\"] = keys\n",
        "            continue\n",
        "\n",
        "        if ANS_RE.match(line.strip()):\n",
        "            mode = 'ans'\n",
        "            continue\n",
        "\n",
        "        if mode == 'ans':\n",
        "            cur[\"answer\"] += raw + \"\\n\"\n",
        "\n",
        "    if cur:\n",
        "        cur[\"answer\"] = cur[\"answer\"].strip()\n",
        "        groups.append(cur)\n",
        "\n",
        "    return groups\n",
        "\n",
        "files = sorted([p for p in RAW_DIR.glob(\"*\") if p.is_file()])\n",
        "if not files:\n",
        "    print(\"‚ö†Ô∏è –£ data/raw –Ω—ñ—á–æ–≥–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ\")\n",
        "else:\n",
        "    print(f\"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª—ñ–≤: {len(files)}\")\n",
        "\n",
        "report = []\n",
        "for p in files:\n",
        "    text, err = safe_read(p)\n",
        "    item = {\"file\": p.name, \"ok\": err is None, \"error\": str(err) if err else \"\"}\n",
        "\n",
        "    if err is None:\n",
        "        st = basic_stats(text)\n",
        "        item.update(st)\n",
        "\n",
        "        # separators (==== etc)\n",
        "        sep_lines = [i+1 for i, ln in enumerate(text.splitlines()) if SEP_RE.match(ln.strip())]\n",
        "        item[\"sep_lines_count\"] = len(sep_lines)\n",
        "        item[\"sep_lines_sample\"] = sep_lines[:10]\n",
        "\n",
        "        # structure check\n",
        "        has_g = bool(re.search(r\"^–ì–†–£–ü–ê\\s+–ó–ê–ü–ò–¢–£:\", text, flags=re.IGNORECASE | re.MULTILINE))\n",
        "        has_k = bool(re.search(r\"^–ö–ª—é—á–æ–≤—ñ\\s+—Å–ª–æ–≤–∞:\", text, flags=re.IGNORECASE | re.MULTILINE))\n",
        "        has_a = bool(re.search(r\"^–í—ñ–¥–ø–æ–≤—ñ–¥—å:\", text, flags=re.IGNORECASE | re.MULTILINE))\n",
        "        item[\"has_groups_format\"] = bool(has_g and has_k and has_a)\n",
        "\n",
        "        groups = parse_groups(text)\n",
        "        item[\"groups_count\"] = len(groups)\n",
        "\n",
        "        # preview first 2 groups\n",
        "        previews = []\n",
        "        for g in groups[:2]:\n",
        "            ans_preview = \" \".join(g[\"answer\"].splitlines()[:3])\n",
        "            ans_preview = re.sub(r\"\\s+\", \" \", ans_preview).strip()\n",
        "            previews.append({\n",
        "                \"title\": g[\"title\"],\n",
        "                \"keys\": g[\"keys\"],\n",
        "                \"answer_preview\": ans_preview[:240] + (\"‚Ä¶\" if len(ans_preview) > 240 else \"\")\n",
        "            })\n",
        "        item[\"groups_preview\"] = previews\n",
        "\n",
        "    report.append(item)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "for r in report:\n",
        "    print(f\"\\nüìÑ {r['file']}\")\n",
        "    if not r[\"ok\"]:\n",
        "        print(\"  ‚ùå Cannot read:\", r[\"error\"])\n",
        "        continue\n",
        "    print(f\"  chars={r['chars']}  lines={r['lines']}  words={r['words']}\")\n",
        "    print(f\"  separators(==== etc): {r['sep_lines_count']}  sample_lines={r['sep_lines_sample']}\")\n",
        "    print(f\"  has_groups_format: {r.get('has_groups_format', False)}  groups_count={r.get('groups_count', 0)}\")\n",
        "    if r.get('groups_preview'):\n",
        "        for i, pv in enumerate(r['groups_preview'], 1):\n",
        "            print(f\"    ‚îú‚îÄ Group {i}: {pv['title']}\")\n",
        "            print(f\"    ‚îÇ  keys: {', '.join(pv['keys'][:12])}{'‚Ä¶' if len(pv['keys'])>12 else ''}\")\n",
        "            print(f\"    ‚îÇ  preview: {pv['answer_preview']}\")\n",
        "    else:\n",
        "        print(\"  (no groups preview)\")\n",
        "print(\"\\n\" + \"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ (–û–ø—Ü—ñ–π–Ω–æ) –î–µ—Ç–∞–ª—å–Ω–∏–π –ø–µ—Ä–µ–≥–ª—è–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª—É\n",
        "–í–≤–µ–¥–∏ —ñ–º‚Äô—è —Ñ–∞–π–ª—É (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥ `biology_basics.txt`) ‚Äî —ñ –ø–æ–¥–∏–≤–∏–º–æ—Å—å –≥—Ä—É–ø–∏ —Ç–∞ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TARGET = \"biology_basics.txt\"  # <-- –∑–º—ñ–Ω–∏, —è–∫—â–æ —Ç—Ä–µ–±–∞\n",
        "p = RAW_DIR / TARGET\n",
        "\n",
        "text, err = safe_read(p)\n",
        "if err:\n",
        "    print(\"‚ùå Cannot read\", TARGET, \":\", err)\n",
        "else:\n",
        "    groups = parse_groups(text)\n",
        "    print(f\"‚úÖ {TARGET}: groups={len(groups)}\")\n",
        "    for i, g in enumerate(groups[:10], 1):\n",
        "        print(\"\\n\" + \"-\"*60)\n",
        "        print(f\"[{i}] {g['title']}\")\n",
        "        print(\"keys:\", \", \".join(g['keys'][:20]) + (\"‚Ä¶\" if len(g['keys'])>20 else \"\"))\n",
        "        ans_lines = [ln for ln in g['answer'].splitlines() if ln.strip()]\n",
        "        print(\"answer first lines:\")\n",
        "        for ln in ans_lines[:6]:\n",
        "            print(\" \", ln)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üßπ (–û–ø—Ü—ñ–π–Ω–æ) –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ ¬´—Å–º—ñ—Ç—Ç—è¬ª —É –≤—ñ–¥–ø–æ–≤—ñ–¥—è—Ö\n",
        "–¶–µ –∫–æ—Ä–∏—Å–Ω–æ, —è–∫—â–æ –≤ –±–∞–∑—ñ –ø–æ–ø–∞–¥–∞—é—Ç—å—Å—è –ª—ñ–Ω—ñ—ó —Ç–∏–ø—É `=====` —ñ –≤–æ–Ω–∏ –ø–æ—Ç—ñ–º –∑‚Äô—è–≤–ª—è—é—Ç—å—Å—è —É –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –±–æ—Ç–∞."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TARGET = \"biology_basics.txt\"\n",
        "p = RAW_DIR / TARGET\n",
        "text, err = safe_read(p)\n",
        "if err:\n",
        "    print(\"‚ùå Cannot read\", TARGET, \":\", err)\n",
        "else:\n",
        "    lines = text.splitlines()\n",
        "    bad = [(i+1, ln) for i, ln in enumerate(lines) if SEP_RE.match(ln.strip())]\n",
        "    print(f\"‚úÖ Found separator-lines: {len(bad)}\")\n",
        "    for i, (lnum, ln) in enumerate(bad[:30], 1):\n",
        "        print(f\"{i:02d}. line {lnum}: {ln}\")\n",
        "    if len(bad) > 30:\n",
        "        print(\"‚Ä¶\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
