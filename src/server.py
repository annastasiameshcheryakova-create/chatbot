import os
from typing import List, Dict
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv

import chromadb
from chromadb.config import Settings
from openai import OpenAI

# ========= CONFIG =========
load_dotenv()

DATA_DIR = "data/raw"
PERSIST_DIR = "vectorstore"
COLLECTION = "kb"

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
if not OPENAI_API_KEY:
    raise RuntimeError("–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ OPENAI_API_KEY. –°—Ç–≤–æ—Ä–∏ .env —ñ –¥–æ–¥–∞–π –∫–ª—é—á.")

client = OpenAI(api_key=OPENAI_API_KEY)

app = FastAPI(title="BioConsult RAG API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –¥–ª—è —Ç–µ—Å—Ç—ñ–≤, –ø–æ—Ç—ñ–º –∫—Ä–∞—â–µ –∑–≤—É–∑–∏—Ç–∏
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

chroma = chromadb.PersistentClient(
    path=PERSIST_DIR,
    settings=Settings(anonymized_telemetry=False)
)

# ========= Utils =========
def ensure_dirs():
    os.makedirs(DATA_DIR, exist_ok=True)
    os.makedirs(PERSIST_DIR, exist_ok=True)

def get_collection():
    return chroma.get_or_create_collection(COLLECTION)

def read_raw_texts() -> List[Dict]:
    ensure_dirs()
    docs = []
    for fn in os.listdir(DATA_DIR):
        if fn.lower().endswith((".txt", ".md")):
            path = os.path.join(DATA_DIR, fn)
            with open(path, "r", encoding="utf-8", errors="ignore") as f:
                docs.append({"id": fn, "title": fn, "text": f.read()})
    return docs

def chunk_text(text: str, chunk_size: int = 900, overlap: int = 120) -> List[str]:
    clean = " ".join((text or "").split())
    if not clean:
        return []
    out = []
    i = 0
    while i < len(clean):
        end = min(len(clean), i + chunk_size)
        out.append(clean[i:end])
        i = max(0, end - overlap)
        if end == len(clean):
            break
    return out

def embed_texts(texts: List[str]) -> List[List[float]]:
    resp = client.embeddings.create(
        model="text-embedding-3-small",
        input=texts
    )
    return [d.embedding for d in resp.data]

# ========= RAG =========
def rebuild_index() -> Dict:
    ensure_dirs()

    # –ø–µ—Ä–µ—Å–æ–∑–¥–∞—î–º–æ –∫–æ–ª–µ–∫—Ü—ñ—é
    try:
        chroma.delete_collection(COLLECTION)
    except Exception:
        pass
    col = chroma.get_or_create_collection(COLLECTION)

    docs = read_raw_texts()
    ids, metadatas, texts = [], [], []

    for d in docs:
        parts = chunk_text(d["text"])
        for i, p in enumerate(parts):
            ids.append(f"{d['id']}#{i}")
            metadatas.append({"title": d["title"], "chunk": i})
            texts.append(p)

    if not texts:
        return {"ok": True, "chunks": 0, "message": "–ù–µ–º–∞—î .txt/.md —É data/raw"}

    batch = 64
    for start in range(0, len(texts), batch):
        sub_texts = texts[start:start + batch]
        sub_ids = ids[start:start + batch]
        sub_meta = metadatas[start:start + batch]
        sub_emb = embed_texts(sub_texts)

        col.add(
            ids=sub_ids,
            documents=sub_texts,
            metadatas=sub_meta,
            embeddings=sub_emb
        )

    return {"ok": True, "chunks": len(texts)}

def retrieve(question: str, k: int = 6) -> List[Dict]:
    col = get_collection()

    q_emb = embed_texts([question])[0]
    res = col.query(query_embeddings=[q_emb], n_results=k)

    docs = res.get("documents", [[]])[0]
    metas = res.get("metadatas", [[]])[0]

    out = []
    for doc, meta in zip(docs, metas):
        out.append({"title": meta.get("title", "kb"), "text": doc})
    return out

# ========= Prompt (–í–ê–ñ–õ–ò–í–û: fallback —è–∫—â–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –Ω–µ–º–∞) =========
def build_messages(question: str, contexts: List[Dict]) -> List[Dict]:
    if contexts:
        context_block = "\n\n".join(
            [f"[{i+1}] ({c['title']}) {c['text']}" for i, c in enumerate(contexts)]
        )

        system = (
            "–¢–∏ BioConsult ‚Äî –¥—Ä—É–∂–Ω—ñ–π –Ω–∞–≤—á–∞–ª—å–Ω–∏–π –∞—Å–∏—Å—Ç–µ–Ω—Ç –∑ –±—ñ–æ–ª–æ–≥—ñ—ó. "
            "–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é, –ø—Ä–æ—Å—Ç–æ —ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–æ. "
            "–ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∏–∂—á–µ ‚Äî —Ü–µ –±–∞–∑–∞ –∑–Ω–∞–Ω—å (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π —ó—ó —è–∫ –¥–∂–µ—Ä–µ–ª–æ). "
            "–ù–ï —Ü–∏—Ç—É–π —É—Ä–∏–≤–∫–∏ –¥–æ—Å–ª—ñ–≤–Ω–æ —ñ –ù–ï –ø–æ–∫–∞–∑—É–π –∫–æ–Ω—Å–ø–µ–∫—Ç–∏. "
            "–Ø–∫—â–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å—É–ø–µ—Ä–µ—á–∏—Ç—å —Ç–≤–æ—ó–º –∑–Ω–∞–Ω–Ω—è–º ‚Äî –¥–æ–≤—ñ—Ä—è–π –∫–æ–Ω—Ç–µ–∫—Å—Ç—É."
        )

        user = (
            f"–ö–û–ù–¢–ï–ö–°–¢ (–¥–ª—è —Ç–µ–±–µ):\n{context_block}\n\n"
            f"–ü–ò–¢–ê–ù–ù–Ø: {question}\n\n"
            "–î–∞–π –≤—ñ–¥–ø–æ–≤—ñ–¥—å:\n"
            "1) –∫–æ—Ä–æ—Ç–∫–æ —Å—É—Ç—å\n"
            "2) –ø–æ—è—Å–Ω–µ–Ω–Ω—è –ø—Ä–æ—Å—Ç–∏–º–∏ —Å–ª–æ–≤–∞–º–∏\n"
            "3) —è–∫—â–æ –¥–æ—Ä–µ—á–Ω–æ ‚Äî —Å–ø–∏—Å–æ–∫/–∫—Ä–æ–∫–∏\n"
        )
        return [{"role": "system", "content": system},
                {"role": "user", "content": user}]
    else:
        # ‚úÖ –ù–µ–º–∞—î –∫–æ–Ω—Ç–µ–∫—Å—Ç—É -> –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î–º–æ –∑—ñ –∑–∞–≥–∞–ª—å–Ω–∏—Ö –∑–Ω–∞–Ω—å
        system = (
            "–¢–∏ BioConsult ‚Äî –¥—Ä—É–∂–Ω—ñ–π –Ω–∞–≤—á–∞–ª—å–Ω–∏–π –∞—Å–∏—Å—Ç–µ–Ω—Ç –∑ –±—ñ–æ–ª–æ–≥—ñ—ó. "
            "–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é, –ø—Ä–æ—Å—Ç–æ —ñ —á—ñ—Ç–∫–æ. "
            "–ü–æ —Ü—å–æ–º—É –ø–∏—Ç–∞–Ω–Ω—é –≤ –±–∞–∑—ñ –∑–Ω–∞–Ω—å –Ω–µ–º–∞—î –∫–æ–Ω—Ç–µ–∫—Å—Ç—É, —Ç–æ–º—É –≤—ñ–¥–ø–æ–≤—ñ–¥–∞–π –∑—ñ —Å–≤–æ—ó—Ö –∑–∞–≥–∞–ª—å–Ω–∏—Ö –∑–Ω–∞–Ω—å. "
            "–Ø–∫—â–æ –Ω–µ –≤–ø–µ–≤–Ω–µ–Ω–∏–π ‚Äî —Å–∫–∞–∂–∏ '–Ω–µ –≤–ø–µ–≤–Ω–µ–Ω–∏–π' —ñ –ø–æ—Å—Ç–∞–≤ 1 —É—Ç–æ—á–Ω—é–≤–∞–ª—å–Ω–µ –ø–∏—Ç–∞–Ω–Ω—è."
        )
        user = (
            f"–ü–ò–¢–ê–ù–ù–Ø: {question}\n\n"
            "–§–æ—Ä–º–∞—Ç:\n"
            "–ü–æ—á–Ω–∏ –∑ —Ñ—Ä–∞–∑–∏ '–¶–µ ...' —ñ –¥–∞–π –∫–æ—Ä–æ—Ç–∫–µ –ø–æ—è—Å–Ω–µ–Ω–Ω—è 2‚Äì6 —Ä–µ—á–µ–Ω–Ω—è–º–∏.\n"
        )
        return [{"role": "system", "content": system},
                {"role": "user", "content": user}]

# ========= API =========
class ChatIn(BaseModel):
    question: str
    rag: bool = True
    top_k: int = 6

class ChatOut(BaseModel):
    answer: str
    used_contexts: int

@app.get("/api/health")
def health():
    return {"ok": True}

@app.post("/api/reindex")
def reindex():
    return rebuild_index()

@app.post("/api/chat", response_model=ChatOut)
def chat(payload: ChatIn):
    question = (payload.question or "").strip()
    if not question:
        return ChatOut(answer="–ù–∞–ø–∏—à–∏ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è üôÇ", used_contexts=0)

    contexts = retrieve(question, payload.top_k) if payload.rag else []
    messages = build_messages(question, contexts)

    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.4
    )

    answer = (resp.choices[0].message.content or "").strip()
    return ChatOut(answer=answer, used_contexts=len(contexts))
